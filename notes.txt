1 - Get real time data
1.1 - Access a list of the SP500 companies
1.1.1 - Tried with url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies' - Didn't work (403 - unauthorized access)
1.1.1.1 - Found the term "user_agent" that basically acts on mt behalf to extract data from a website. I looked for specificities for Perplexitie's COMET browser and found this one that works "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36"
1.1.2 - Used Beautiful soup for the first time and understood what it is all about (One strategy I use here is to paste the code that Perplexity gives me and say what I understand about it and ask Perplexity if I'm getting things rigth. Basically what we did was to first have an object "html-parser" to be able to extract data from that URL and use another one to find the table with the ID = consituents to get the right table â€” I was able to confirm this because I know a little bit about html and inspected the page to find the table's ID)
1.1.2.1 - Tried to use pandas reading function for HTML but lxml lib was missing. Had to install that first.
1.1.2.2 - Was having trouble identifying why I was putting "table" under a string to get it to work in Padndas. Undertood that pd.read_html expects a string, but "table" was actually a soup object. So it makes sense. And adding the index [0] always extract the first table, in case we have more tables being extracted.
1.2 - Getting financial information from yfinance
1.2.1 - Never used yfinance before, but basically understood that we need to define a function to get the financial data for all tickers we want. This is separate from the table we fetched in the HTML wikipedia. This function starts by using one parameter (ticker), then defines stock as that parameter and then the information on the stock as the stock.info. Then we return the assign Ticker to be the ticker parameter and we get the financial with the info.get() function, that basically retrieves the information we want out of the dictionary info. Then we assing the variable Tickers to be a list of the tickers we want to extract (this is the part where we are going to fetch tickers from our table -- that we extracted in wikipedia -- creating a list). Then we assing fundamental_data as a list of the get_fundamental_data(ticker) function and run a loop for every tikcer in our Ticker list. And then we transform the result into a readable pandas dataframe
1.2.2 - To extract all financial data that I wanted (Price to earnings, price to book, price to sales, dividend yield, ebitda and price), I just went on to Perplexity and asked to give me the corresponding variables.
1.2.3 - One of the issues that I read was being exposed to rate limits to get all data for the 503 stocks. To work around this, I asked Perplexity what to and tried to understand what needed to be change. From wahat I could understood, all I had to do is to set up a time delay before each ticker, meaning that the function would wait some seconds between each fetch. This would result on taking 2 seconds per fetch, it will 16 minutes to get all data.
1.2.3.1 - I tried and found a way to get all data faster, using the yahooquery library. To test, I just created a new file, copied the code I had in my main.py file and saw if it worked. I'm still grasping on the core concept of what I just did but understanding what it means. What I'll do is I'm going to create the project all over again each time I open it, to see if I get the core concepts together and learn from that. And I prefer to take it slow (meaning doing fewer steps), but making sure I understand everything.
1.2.3.2 - Faced a problem when pulling all data (variable names were not correct for ebitda, pbRatio and current price), so, again, I wen to Perplexity to try and find a solution for this. I might have to pull data from other places other than summary_details.
1.2.3.3 - Tried to use multiple ways to get the data (either summary_details and financial data but it was duplicating efforts, so I just wen with one of them -- asked perplexity which one would be) -- took too much time with 30 requests. Will need to do this later and explore other options. (more than 5 minutes)


